{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpCQBezcxJD1"
      },
      "source": [
        "# 02456 Molecular Property Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXmf6uiTxJD2"
      },
      "source": [
        "Basic example of how to train the PaiNN model to predict the QM9 property\n",
        "\"internal energy at 0K\". This property (and the majority of the other QM9\n",
        "properties) is computed as a sum of atomic contributions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6S8SmwK8xJD2"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install pytorch_lightning\n",
        "!pip install torch_geometric\n",
        "\n",
        "import torch\n",
        "import argparse\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "from tqdm import trange\n",
        "from pytorch_lightning import seed_everything\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.datasets import QM9\n",
        "from torch_geometric.loader import DataLoader\n",
        "from typing import Optional, List, Union, Tuple\n",
        "from torch_geometric.transforms import BaseTransform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcfhMz50xJD3"
      },
      "source": [
        "## QM9 Datamodule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vZY82V6DxJD4"
      },
      "outputs": [],
      "source": [
        "class GetTarget(BaseTransform):\n",
        "\n",
        "    def __init__(self, target: Optional[int] = None) -> None:\n",
        "        self.target = [target]\n",
        "\n",
        "\n",
        "    def forward(self, data: Data) -> Data:\n",
        "        if self.target is not None:\n",
        "            data.y = data.y[:, self.target]\n",
        "        return data\n",
        "\n",
        "\n",
        "class QM9DataModule(pl.LightningDataModule):\n",
        "\n",
        "    target_types = ['atomwise' for _ in range(19)]\n",
        "    target_types[0] = 'dipole_moment'\n",
        "    target_types[5] = 'electronic_spatial_extent'\n",
        "\n",
        "    # Specify unit conversions (eV to meV).\n",
        "    unit_conversion = {\n",
        "        i: (lambda t: 1000*t) if i not in [0, 1, 5, 11, 16, 17, 18]\n",
        "        else (lambda t: t)\n",
        "        for i in range(19)\n",
        "    }\n",
        "\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        target: int = 7,\n",
        "        data_dir: str = 'data/',\n",
        "        batch_size_train: int = 100,\n",
        "        batch_size_inference: int = 1000,\n",
        "        num_workers: int = 0,\n",
        "        splits: Union[List[int], List[float]] = [110000, 10000, 10831],\n",
        "        seed: int = 0,\n",
        "        subset_size: Optional[int] = None,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.target = target\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size_train = batch_size_train\n",
        "        self.batch_size_inference = batch_size_inference\n",
        "        self.num_workers = num_workers\n",
        "        self.splits = splits\n",
        "        self.seed = seed\n",
        "        self.subset_size = subset_size\n",
        "\n",
        "        self.data_train = None\n",
        "        self.data_val = None\n",
        "        self.data_test = None\n",
        "\n",
        "\n",
        "    def prepare_data(self) -> None:\n",
        "        # Download data\n",
        "        QM9(root=self.data_dir)\n",
        "\n",
        "\n",
        "    def setup(self, stage: Optional[str] = None) -> None:\n",
        "        dataset = QM9(root=self.data_dir, transform=GetTarget(self.target))\n",
        "\n",
        "        # Shuffle dataset\n",
        "        rng = np.random.default_rng(seed=self.seed)\n",
        "        dataset = dataset[rng.permutation(len(dataset))]\n",
        "\n",
        "        # Subset dataset\n",
        "        if self.subset_size is not None:\n",
        "            dataset = dataset[:self.subset_size]\n",
        "\n",
        "        # Split dataset\n",
        "        if all([type(split) == int for split in self.splits]):\n",
        "            split_sizes = self.splits\n",
        "        elif all([type(split) == float for split in self.splits]):\n",
        "            split_sizes = [int(len(dataset) * prop) for prop in self.splits]\n",
        "\n",
        "        split_idx = np.cumsum(split_sizes)\n",
        "        self.data_train = dataset[:split_idx[0]]\n",
        "        self.data_val = dataset[split_idx[0]:split_idx[1]]\n",
        "        self.data_test = dataset[split_idx[1]:]\n",
        "\n",
        "\n",
        "    def get_target_stats(\n",
        "        self,\n",
        "        remove_atom_refs: bool = True,\n",
        "        divide_by_atoms: bool = True\n",
        "    ) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]:\n",
        "        atom_refs = self.data_train.atomref(self.target)                        # Atom reference energy\n",
        "\n",
        "        ys = list()\n",
        "        for batch in self.train_dataloader(shuffle=False):\n",
        "            y = batch.y.clone()\n",
        "            if remove_atom_refs and atom_refs is not None:\n",
        "                y.index_add_(\n",
        "                    dim=0, index=batch.batch, source=-atom_refs[batch.z]\n",
        "                )\n",
        "            if divide_by_atoms:                                                 # Normalize internal energy by the number of atoms\n",
        "                _, num_atoms  = torch.unique(batch.batch, return_counts=True)\n",
        "                y = y / num_atoms.unsqueeze(-1)\n",
        "            ys.append(y)\n",
        "\n",
        "        y = torch.cat(ys, dim=0)\n",
        "        return y.mean(), y.std(), atom_refs\n",
        "\n",
        "\n",
        "    def train_dataloader(self, shuffle: bool = True) -> DataLoader:\n",
        "        return DataLoader(\n",
        "            self.data_train,\n",
        "            batch_size=self.batch_size_train,\n",
        "            num_workers=self.num_workers,\n",
        "            shuffle=shuffle,\n",
        "            pin_memory=True,\n",
        "        )\n",
        "\n",
        "\n",
        "    def val_dataloader(self) -> DataLoader:\n",
        "        return DataLoader(\n",
        "            self.data_val,\n",
        "            batch_size=self.batch_size_inference,\n",
        "            num_workers=self.num_workers,\n",
        "            shuffle=False,\n",
        "            pin_memory=True,\n",
        "        )\n",
        "\n",
        "\n",
        "    def test_dataloader(self) -> DataLoader:\n",
        "        return DataLoader(\n",
        "            self.data_test,\n",
        "            batch_size=self.batch_size_inference,\n",
        "            num_workers=self.num_workers,\n",
        "            shuffle=False,\n",
        "            pin_memory=True,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-Oevac1xJD5"
      },
      "source": [
        "## Post-processing module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3WkWe76xJD5"
      },
      "outputs": [],
      "source": [
        "class AtomwisePostProcessing(nn.Module):\n",
        "    \"\"\"\n",
        "    Post-processing for (QM9) properties that are predicted as sums of atomic\n",
        "    contributions.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_outputs: int,\n",
        "        mean: torch.FloatTensor,\n",
        "        std: torch.FloatTensor,\n",
        "        atom_refs: torch.FloatTensor,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            num_outputs: Integer with the number of model outputs. In most\n",
        "                cases 1.\n",
        "            mean: torch.FloatTensor with mean value to shift atomwise\n",
        "                contributions by.\n",
        "            std: torch.FloatTensor with standard deviation to scale atomwise\n",
        "                contributions by.\n",
        "            atom_refs: torch.FloatTensor of size [num_atom_types, 1] with\n",
        "                atomic reference values.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_outputs = num_outputs\n",
        "        self.register_buffer('scale', std)\n",
        "        self.register_buffer('shift', mean)\n",
        "        self.atom_refs = nn.Embedding.from_pretrained(atom_refs, freeze=True)\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        atomic_contributions: torch.FloatTensor,\n",
        "        atoms: torch.LongTensor,\n",
        "        graph_indexes: torch.LongTensor,\n",
        "    ) -> torch.FloatTensor:\n",
        "        \"\"\"\n",
        "        Atomwise post-processing operations and atomic sum.\n",
        "\n",
        "        Args:\n",
        "            atomic_contributions: torch.FloatTensor of size [num_nodes,\n",
        "                num_outputs] with each node's contribution to the overall graph\n",
        "                prediction, i.e., each atom's contribution to the overall\n",
        "                molecular property prediction.\n",
        "            atoms: torch.LongTensor of size [num_nodes] with atom type of each\n",
        "                node in the graph.\n",
        "            graph_indexes: torch.LongTensor of size [num_nodes] with the graph\n",
        "                index each node belongs to.\n",
        "\n",
        "        Returns:\n",
        "            A torch.FLoatTensor of size [num_graphs, num_outputs] with\n",
        "            predictions for each graph (molecule).\n",
        "        \"\"\"\n",
        "        num_graphs = torch.unique(graph_indexes).shape[0]\n",
        "\n",
        "        atomic_contributions = atomic_contributions*self.scale + self.shift\n",
        "        atomic_contributions = atomic_contributions + self.atom_refs(atoms)\n",
        "\n",
        "        # Sum contributions for each graph\n",
        "        output_per_graph = torch.zeros(\n",
        "            (num_graphs, self.num_outputs),\n",
        "            device=atomic_contributions.device,\n",
        "        )\n",
        "        output_per_graph.index_add_(\n",
        "            dim=0,\n",
        "            index=graph_indexes,\n",
        "            source=atomic_contributions,\n",
        "        )\n",
        "\n",
        "        return output_per_graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1-c0ITwxJD6"
      },
      "source": [
        "## PaiNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def atom_distances(atom_positions,\n",
        "                   graph_indexes,\n",
        "                   cutoff_dist):\n",
        "    \"\"\"\n",
        "    Computes pairwise distances between atoms within each molecule in the batch,\n",
        "    and filters out pairs beyond the cutoff distance.\n",
        "\n",
        "    Args:\n",
        "        atom_positions: torch.FloatTensor of size [num_nodes, 3] with\n",
        "                euclidean coordinates of each node / atom.\n",
        "        graph_indexes: torch.LongTensor of size [num_nodes] with the graph\n",
        "                index each node belongs to.\n",
        "        cutoff_dist: Euclidean distance threshold for determining whether\n",
        "                two nodes (atoms) are neighbours.\n",
        "    \"\"\"\n",
        "    edge_index = []\n",
        "    distances = []\n",
        "\n",
        "    # Iterate over unique molecules in the batch\n",
        "    for mol_id in torch.unique(graph_indexes):\n",
        "\n",
        "        # Mask to filter atoms belonging to the current molecule\n",
        "        atom_mask = (graph_indexes == mol_id)\n",
        "\n",
        "        # Extract positions of atoms in this molecule\n",
        "        pos = atom_positions[atom_mask]\n",
        "\n",
        "        # Compute pairwise distance matrix for atoms in this molecule\n",
        "        # torch.cdist computes batched the p-norm distance between each pair of the two collections of row vectors.\n",
        "        dist_matrix = torch.cdist(pos, pos)\n",
        "\n",
        "        # Find indices where distance is below cutoff (ignoring self-loops)\n",
        "        src, dst = torch.where((dist_matrix < cutoff_dist) & (dist_matrix > 0))\n",
        "\n",
        "        # Store the edges and distances\n",
        "        edge_index.append(torch.stack([src, dst]))\n",
        "        distances.append(dist_matrix[src, dst])\n",
        "\n",
        "    # Concatenate all edges and distances across molecules\n",
        "    edge_index = torch.cat(edge_index, dim=1) if edge_index else torch.empty(2, 0, dtype=torch.long)\n",
        "    distances = torch.cat(distances) if distances else torch.empty(0)\n",
        "\n",
        "    return edge_index, distances\n",
        "\n",
        "\n",
        "def atom_distiance(atom_positions,\n",
        "                   graph_indexes,\n",
        "                   cutoff_dist):\n",
        "\n",
        "  j, i = graph_indexes\n",
        "  distance_vec = atom_positions[j] - atom_positions[i]\n",
        "  edge_distance = distance_vec.norm()\n",
        "\n",
        "  return edge_distance\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Message(sj, vj, r_ij, num_features):\n",
        "\n",
        "  # Linear combinations of the atom embeddings.\n",
        "  s_proj = nn.Sequential(nn.Linear(num_features, num_features),\n",
        "                     ScaledSiLU(),\n",
        "                     nn.Linear(num_features, num_features * 3))\n",
        "\n",
        "  # Linear combinations of the radial basis funtions.\n",
        "  rbf_proj = nn.Linear(num_rbf_features, num_features * 3)\n",
        "\n",
        "  phi_W_product = sj * # Linear combinations of RBF\n",
        "\n",
        "  split_1, split_2, split_3 = phi_W_product #splitted\n",
        "\n",
        "  vj = sum(vj * split_1) + sum(r_ij * split_3)\n",
        "\n",
        "  return ds, dv\n",
        "\n",
        "def Update(sj, vj):\n",
        "\n",
        "  self.hidden_channels = hidden_channels\n",
        "\n",
        "  linear_link_U = nn.Linear(hidden_channels, hidden_channels * 2, bias=False)\n",
        "\n",
        "  linear_link_V = nn.Linear(hidden_channels, hidden_channels * 2, bias=False)\n",
        "\n",
        "  linear_link_W = nn.Sequential(nn.Linear(hidden_channels * 2, hidden_channels),\n",
        "                                ScaledSiLU(),\n",
        "                                nn.Linear(hidden_channels, hidden_channels * 3),\n",
        "                                )\n",
        "\n",
        "  vj_dot = (Uvj * Vvj).sum(dim=1) * split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "RFYhPsszAFOd",
        "outputId": "752d3002-dda4-425c-8473-8295fd32c93a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-2-27c6b005b73d>, line 48)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-27c6b005b73d>\"\u001b[0;36m, line \u001b[0;32m48\u001b[0m\n\u001b[0;31m    nn.Linear(hidden_channels, hidden_channels * 3)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAV3BSZoxJD7"
      },
      "outputs": [],
      "source": [
        "class MessageBlock(nn.Module):\n",
        "  def __init__(self, *args, **kwargs)\n",
        "    super().__init__()\n",
        "\n",
        "    self.linear_1 = nn.Linear(...)\n",
        "\n",
        "\n",
        "  def forward(self, *args, **kwargs):\n",
        "    ... = self.linear_1(...)\n",
        "\n",
        "    return ...\n",
        "\n",
        "class PaiNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Polarizable Atom Interaction Neural Network with PyTorch.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_message_passing_layers: int = 3,\n",
        "        num_features: int = 128,\n",
        "        num_outputs: int = 1,\n",
        "        num_rbf_features: int = 20,\n",
        "        num_unique_atoms: int = 100,\n",
        "        cutoff_dist: float = 5.0,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            num_message_passing_layers: Number of message passing layers in\n",
        "                the PaiNN model.\n",
        "            num_features: Size of the node embeddings (scalar features) and\n",
        "                vector features.\n",
        "            num_outputs: Number of model outputs. In most cases 1.\n",
        "            num_rbf_features: Number of radial basis functions to represent\n",
        "                distances.\n",
        "            num_unique_atoms: Number of unique atoms in the data that we want\n",
        "                to learn embeddings for.\n",
        "            cutoff_dist: Euclidean distance threshold for determining whether\n",
        "                two nodes (atoms) are neighbours.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_message_passing_layers = num_message_passing_layers\n",
        "        self.num_features = num_features\n",
        "        self.num_outputs = num_outputs\n",
        "        self.num_rbf_features = num_rbf_features\n",
        "        self.num_unique_atoms = num_unique_atoms\n",
        "        self.cutoff_dist = cutoff_dist\n",
        "        self.device = device\n",
        "\n",
        "        self.embedding_s = nn.Embedding(num_unique_atoms, num_features)\n",
        "        self.embedding_v = nn.Embedding(3, num_features, sparse=True)\n",
        "\n",
        "        self.message_1 = MessageBlock(...)\n",
        "        self.message_2 = MessageBlock(..)\n",
        "        self.update = Update()\n",
        "        self.output = Output()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        atoms: torch.LongTensor,\n",
        "        atom_positions: torch.FloatTensor,\n",
        "        graph_indexes: torch.LongTensor,\n",
        "    ) -> torch.FloatTensor:\n",
        "        \"\"\"\n",
        "        Forward pass of PaiNN. Includes the readout network highlighted in blue\n",
        "        in Figure 2 in (Schütt et al., 2021) with normal linear layers which is\n",
        "        used for predicting properties as sums of atomic contributions. The\n",
        "        post-processing and final sum is perfomed with\n",
        "        src.models.AtomwisePostProcessing.\n",
        "\n",
        "        Args:\n",
        "            atoms: torch.LongTensor of size [num_nodes] with atom type of each\n",
        "                node in the graph.\n",
        "            atom_positions: torch.FloatTensor of size [num_nodes, 3] with\n",
        "                euclidean coordinates of each node / atom.\n",
        "            graph_indexes: torch.LongTensor of size [num_nodes] with the graph\n",
        "                index each node belongs to.\n",
        "\n",
        "        Returns:\n",
        "            A torch.FloatTensor of size [num_nodes, num_outputs] with atomic\n",
        "            contributions to the overall molecular property prediction.\n",
        "        \"\"\"\n",
        "        # ----------------------------------------------------------------------\n",
        "        # Initialization\n",
        "\n",
        "        s = self.embedding_s(atoms)\n",
        "        v = self.embedding_v(atoms)\n",
        "\n",
        "        # ----------------------------------------------------------------------\n",
        "\n",
        "        # Connections???\n",
        "\n",
        "        # ----------------------------------------------------------------------\n",
        "        # Message and update\n",
        "\n",
        "        for message, update in zip(self.message_blocks, self.update_blocks):\n",
        "            messa\n",
        "        for i in range(3):\n",
        "\n",
        "          # Message\n",
        "          ds, dv = self.message(s, v, edge_index, edge_rbf, edge_vector)\n",
        "          s = s + ds\n",
        "          v = v + dv\n",
        "\n",
        "          # Update\n",
        "          ds, dv = self.update(s, v)\n",
        "          s = s + ds\n",
        "          v = v + dv\n",
        "\n",
        "        # ----------------------------------------------------------------------\n",
        "\n",
        "        # Output step\n",
        "\n",
        "        # ----------------------------------------------------------------------\n",
        "\n",
        "\n",
        "        # Final output\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n-d1iJtxJD8"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5VcXhSQ0xJD8"
      },
      "outputs": [],
      "source": [
        "def cli(args: list = []):\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--seed', default=0)\n",
        "\n",
        "    # Data\n",
        "    parser.add_argument('--target', default=7, type=int) # 7 => Internal energy at 0K\n",
        "    parser.add_argument('--data_dir', default='data/', type=str)\n",
        "    parser.add_argument('--batch_size_train', default=100, type=int)\n",
        "    parser.add_argument('--batch_size_inference', default=1000, type=int)\n",
        "    parser.add_argument('--num_workers', default=0, type=int)\n",
        "    parser.add_argument('--splits', nargs=3, default=[110000, 10000, 10831], type=int) # [num_train, num_val, num_test]\n",
        "    parser.add_argument('--subset_size', default=None, type=int)\n",
        "\n",
        "    # Model\n",
        "    parser.add_argument('--num_message_passing_layers', default=3, type=int)\n",
        "    parser.add_argument('--num_features', default=128, type=int)\n",
        "    parser.add_argument('--num_outputs', default=1, type=int)\n",
        "    parser.add_argument('--num_rbf_features', default=20, type=int)\n",
        "    parser.add_argument('--num_unique_atoms', default=100, type=int)\n",
        "    parser.add_argument('--cutoff_dist', default=5.0, type=float)\n",
        "\n",
        "    # Training\n",
        "    parser.add_argument('--lr', default=5e-4, type=float)\n",
        "    parser.add_argument('--weight_decay', default=0.01, type=float)\n",
        "    parser.add_argument('--num_epochs', default=1000, type=int)\n",
        "\n",
        "    args = parser.parse_args(args=args)\n",
        "    return args"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xsfP4uYxJD8"
      },
      "source": [
        "## Training and testing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify non-default arguments in this list.\n",
        "args = []\n",
        "args = cli(args)\n",
        "seed_everything(args.seed)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Load and prepare data from the QM9 data set.\n",
        "dm = QM9DataModule(\n",
        "    target=args.target,\n",
        "    data_dir=args.data_dir,\n",
        "    batch_size_train=args.batch_size_train,\n",
        "    batch_size_inference=args.batch_size_inference,\n",
        "    num_workers=args.num_workers,\n",
        "    splits=args.splits,\n",
        "    seed=args.seed,\n",
        "    subset_size=args.subset_size,\n",
        ")\n",
        "dm.prepare_data()\n",
        "dm.setup()\n",
        "\n",
        "# Calculate target statistics.\n",
        "y_mean, y_std, atom_refs = dm.get_target_stats(\n",
        "    remove_atom_refs=True, divide_by_atoms=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTXpHMR1bmqt",
        "outputId": "1e629362-c1af-453b-97fb-661377977d6d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 0\n",
            "Downloading https://data.pyg.org/datasets/qm9_v3.zip\n",
            "Extracting data/raw/qm9_v3.zip\n",
            "Processing...\n",
            "Using a pre-processed version of the dataset. Please install 'rdkit' to alternatively process the raw data.\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "IK2gdRmhxJD8",
        "outputId": "ec475309-c24d-4db0-f93a-87cf1d0d5507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 0\n",
            "  0%|          | 0/1000 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "MessagePassingLayer.forward() missing 1 required positional argument: 'edge_index'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-b463b063ec92>\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         atomic_contributions = painn(\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0matoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0matom_positions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-aa9e89aaa4e3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, atoms, atom_positions, graph_indexes)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# Apply message passing layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0matom_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matom_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrbf_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# Aggregate atomic features to get the molecule-level prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: MessagePassingLayer.forward() missing 1 required positional argument: 'edge_index'"
          ]
        }
      ],
      "source": [
        "\n",
        "# Initialize the model.\n",
        "painn = PaiNN(\n",
        "    num_message_passing_layers=args.num_message_passing_layers,     # 3\n",
        "    num_features=args.num_features,                                 # 128\n",
        "    num_outputs=args.num_outputs,                                   # 1\n",
        "    num_rbf_features=args.num_rbf_features,\n",
        "    num_unique_atoms=args.num_unique_atoms,\n",
        "    cutoff_dist=args.cutoff_dist,                                   # 5\n",
        ")\n",
        "\n",
        "post_processing = AtomwisePostProcessing(\n",
        "    args.num_outputs, y_mean, y_std, atom_refs\n",
        ")\n",
        "\n",
        "painn.to(device)\n",
        "post_processing.to(device)\n",
        "\n",
        "# Define optimizer.\n",
        "optimizer = torch.optim.AdamW(\n",
        "    painn.parameters(),\n",
        "    lr=args.lr,\n",
        "    weight_decay=args.weight_decay,\n",
        ")\n",
        "\n",
        "# Train the model.\n",
        "painn.train()\n",
        "pbar = trange(args.num_epochs)\n",
        "for epoch in pbar:\n",
        "\n",
        "    loss_epoch = 0.\n",
        "    for batch in dm.train_dataloader():\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        atomic_contributions = painn(\n",
        "            atoms=batch.z,\n",
        "            atom_positions=batch.pos,\n",
        "            graph_indexes=batch.batch\n",
        "        )\n",
        "        preds = post_processing(\n",
        "            atoms=batch.z,\n",
        "            graph_indexes=batch.batch,\n",
        "            atomic_contributions=atomic_contributions,\n",
        "        )\n",
        "        loss_step = F.mse_loss(preds, batch.y, reduction='sum')\n",
        "\n",
        "        loss = loss_step / len(batch.y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_epoch += loss_step.detach().item()\n",
        "    loss_epoch /= len(dm.data_train)\n",
        "    pbar.set_postfix_str(f'Train loss: {loss_epoch:.3e}')\n",
        "\n",
        "mae = 0\n",
        "painn.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in dm.test_dataloader():\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        atomic_contributions = painn(\n",
        "            atoms=batch.z,\n",
        "            atom_positions=batch.pos,\n",
        "            graph_indexes=batch.batch,\n",
        "        )\n",
        "        preds = post_processing(\n",
        "            atoms=batch.z,\n",
        "            graph_indexes=batch.batch,\n",
        "            atomic_contributions=atomic_contributions,\n",
        "        )\n",
        "        mae += F.l1_loss(preds, batch.y, reduction='sum')\n",
        "\n",
        "mae /= len(dm.data_test)\n",
        "unit_conversion = dm.unit_conversion[args.target]\n",
        "print(f'Test MAE: {unit_conversion(mae):.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoPQa1tPxJD9",
        "outputId": "8f380af6-1cf5-49cb-ff33-fdb8df3e4656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 110000\n",
            "Validation set size: 10000\n",
            "Test set size: 10831\n",
            "Sample features: Data(x=[13, 11], edge_index=[2, 26], edge_attr=[26, 4], y=[1, 1], pos=[13, 3], idx=[1], name='gdb_2329', z=[13])\n",
            "Atom type (z): tensor([8, 6, 6, 6, 8, 6, 8, 1, 1, 1, 1, 1, 1])\n",
            "Atom position (pos): tensor([[-0.4970,  1.2608, -0.4083],\n",
            "        [-0.2214, -0.0731, -0.1197],\n",
            "        [-0.3092, -0.6333,  1.2750],\n",
            "        [-1.3466, -1.0139,  0.2482],\n",
            "        [-2.6112, -0.4155,  0.4511],\n",
            "        [-3.2778, -0.0487, -0.6749],\n",
            "        [-4.3477,  0.4762, -0.6321],\n",
            "        [-1.0897,  1.6111,  0.2655],\n",
            "        [ 0.5573, -0.4431, -0.7776],\n",
            "        [ 0.4061, -1.3830,  1.5939],\n",
            "        [-0.6500,  0.0318,  2.0625],\n",
            "        [-1.3897, -2.0286, -0.1362],\n",
            "        [-2.7250, -0.2967, -1.5982]])\n",
            "Edge indices (edge_index): tensor([[ 0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,  3,  3,  3,  4,  4,  5,  5,\n",
            "          5,  6,  7,  8,  9, 10, 11, 12],\n",
            "        [ 1,  7,  0,  2,  3,  8,  1,  3,  9, 10,  1,  2,  4, 11,  3,  5,  4,  6,\n",
            "         12,  5,  0,  1,  2,  2,  3,  5]])\n",
            "Target properties (y): tensor([[-10383.3389]])\n",
            "Target mean: tensor(-4.2433)\n",
            "Target standard deviation: tensor(0.1888)\n"
          ]
        }
      ],
      "source": [
        "# Check sizes of train, validation, and test splits:\n",
        "print(\"Training set size:\", len(dm.data_train))\n",
        "print(\"Validation set size:\", len(dm.data_val))\n",
        "print(\"Test set size:\", len(dm.data_test))\n",
        "\n",
        "# View the first sample in the training dataset:\n",
        "sample = dm.data_train[0]\n",
        "print(\"Sample features:\", sample)\n",
        "\n",
        "# Access individual attributes of the sample which we will use:\n",
        "print(\"Atom type (z):\", sample.z)                       # Atom type for each node in the graph\n",
        "print(\"Atom position (pos):\", sample.pos)               # Atom position for each node in the graph\n",
        "print(\"Edge indices (edge_index):\", sample.edge_index)  # Connectivity info between atoms\n",
        "print(\"Target properties (y):\", sample.y)               # Target property (energy)\n",
        "\n",
        "# Print the mean and standard deviation for the target property\n",
        "print(\"Target mean:\", y_mean)\n",
        "print(\"Target standard deviation:\", y_std)\n",
        "\n",
        "# Print atom reference values (standardized contributions of individual atoms to internal energy)\n",
        "#print(\"Atom reference values:\", atom_refs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = dm.data_train[0:2]\n",
        "\n",
        "\n",
        "def atom_vector(atom_positions,\n",
        "                graph_indexes,\n",
        "                cutoff_dist):\n",
        "\n",
        "  distance_vec = torch.zeros(graph_indexes.size()[1], 3)\n",
        "  k = 0\n",
        "  #print(distance_vec)\n",
        "  print(distance_vec[k])\n",
        "\n",
        "  for i in graph_indexes[0].tolist():\n",
        "    for j in graph_indexes[1].tolist():\n",
        "      r_ij = atom_positions[j] - atom_positions[i]\n",
        "      #print(r_ij)\n",
        "      distance_vec[k] = r_ij\n",
        "      k = k + 1\n",
        "\n",
        "  return distance_vec\n",
        "#edge_distance[i, j, 3] = distance_vec.norm()\n",
        "\n",
        "\n",
        "#z = torch.zeros((10,1))\n",
        "#torch.cat((your_tensor,z),1)\n",
        "\n",
        "#return edge_distance\n",
        "\n",
        "\n",
        "atom_vector(sample.pos,\n",
        "            sample.edge_index,\n",
        "            2)\n",
        "\n",
        "#compute_pairwise_distances(sample.pos,\n",
        "                           #torch.ones(sample.z.size()),\n",
        "                           #2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "NtKG-0jwFlC7",
        "outputId": "4e82fb25-22db-4099-cf91-e02ccdf1fd20"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0., 0.])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 64 is out of bounds for dimension 0 with size 64",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-aa8b087bd4fb>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m atom_vector(sample.pos,\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             2)\n",
            "\u001b[0;32m<ipython-input-77-aa8b087bd4fb>\u001b[0m in \u001b[0;36matom_vector\u001b[0;34m(atom_positions, graph_indexes, cutoff_dist)\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mr_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matom_positions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0matom_positions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0;31m#print(r_ij)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       \u001b[0mdistance_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_ij\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m       \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 64 is out of bounds for dimension 0 with size 64"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "distance_vec = torch.zeros(10, 3)\n",
        "\n",
        "distance_vec[1] = torch.ones(3)\n",
        "\n",
        "distance_vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "712dDSPAn1FA",
        "outputId": "55f63df9-e8d3-45fc-fa6f-8b93b7047739"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [1., 1., 1.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = dm.data_train[0:2]\n",
        "for i in sample.edge_index.tolist():\n",
        "  print(i)\n",
        "\n",
        "sample.edge_index[0].tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XW5_bFI2fzSQ",
        "outputId": "5b1fdd39-0084-4d78-acb7-2c1cfc64b4bb"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 5, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 13, 14, 14, 14, 14, 15, 15, 15, 15, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18, 19, 19, 19, 20, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
            "[1, 7, 0, 2, 3, 8, 1, 3, 9, 10, 1, 2, 4, 11, 3, 5, 4, 6, 12, 5, 0, 1, 2, 2, 3, 5, 14, 22, 23, 24, 13, 15, 25, 26, 14, 16, 17, 27, 15, 17, 15, 16, 18, 28, 17, 19, 20, 29, 18, 30, 31, 18, 21, 20, 13, 13, 13, 14, 14, 15, 17, 18, 19, 19]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 4,\n",
              " 4,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 13,\n",
              " 13,\n",
              " 13,\n",
              " 14,\n",
              " 14,\n",
              " 14,\n",
              " 14,\n",
              " 15,\n",
              " 15,\n",
              " 15,\n",
              " 15,\n",
              " 16,\n",
              " 16,\n",
              " 17,\n",
              " 17,\n",
              " 17,\n",
              " 17,\n",
              " 18,\n",
              " 18,\n",
              " 18,\n",
              " 18,\n",
              " 19,\n",
              " 19,\n",
              " 19,\n",
              " 20,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 30,\n",
              " 31]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "painn",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}